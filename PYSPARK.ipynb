{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PYSPARK.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFpMZlSv7e3h",
        "outputId": "37b708f9-7f1d-4002-cf7d-1aeaed54a7e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 40 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 46.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=30c7565fb2d019062f3f4d2fa93c8d3c6be8c63708f1e6faa1468d213526ab41\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark=SparkSession.builder.appName('Logistic Regression').getOrCreate()"
      ],
      "metadata": {
        "id": "pxq3uwLd7rGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression"
      ],
      "metadata": {
        "id": "ZZ4WfVD_8K5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.format(\"libsvm\").load(\"/content/drive/MyDrive/0.MKCE/20.ML with Spark/sample_libsvm_data.txt\")"
      ],
      "metadata": {
        "id": "OLJSL5AK8WKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)"
      ],
      "metadata": {
        "id": "sKPTOx9z9Rhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "lrModel = lr.fit(df)"
      ],
      "metadata": {
        "id": "zo-mvGyXF6LU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the coefficients and intercept for logistic regression\n",
        "print(\"Coefficients: \" + str(lrModel.coefficients))\n",
        "print(\"Intercept: \" + str(lrModel.intercept))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuQgDzSOF8x9",
        "outputId": "27bec1a6-71b2-46a8-c075-9bae1ac2974a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: (692,[272,300,323,350,351,378,379,405,406,407,428,433,434,435,455,456,461,462,483,484,489,490,496,511,512,517,539,540,568],[-7.52068987138421e-05,-8.115773146847101e-05,3.814692771846369e-05,0.0003776490540424337,0.00034051483661944103,0.0005514455157343105,0.0004085386116096913,0.000419746733274946,0.0008119171358670028,0.0005027708372668751,-2.3929260406601844e-05,0.000574504802090229,0.0009037546426803721,7.818229700244018e-05,-2.1787551952912764e-05,-3.4021658217896256e-05,0.0004966517360637634,0.0008190557828370367,-8.017982139522704e-05,-2.7431694037836214e-05,0.0004810832226238988,0.00048408017626778765,-8.926472920011488e-06,-0.00034148812330427335,-8.950592574121486e-05,0.00048645469116892167,-8.478698005186209e-05,-0.0004234783215831763,-7.29653577763134e-05])\n",
            "Intercept: -0.5991460286401435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# We can also use the multinomial family for binary classification\n",
        "mlr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8, family=\"multinomial\")\n"
      ],
      "metadata": {
        "id": "ZUEi7I6fF_CH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Fit the model\n",
        "mlrModel = mlr.fit(df)\n"
      ],
      "metadata": {
        "id": "FgJ54_m2I9JU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Print the coefficients and intercepts for logistic regression with multinomial family\n",
        "print(\"Multinomial coefficients: \" + str(mlrModel.coefficientMatrix))\n",
        "print(\"Multinomial intercepts: \" + str(mlrModel.interceptVector))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85uN71hVI_F9",
        "outputId": "40e02a77-005a-4e04-f825-6ca52748a844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multinomial coefficients: 2 X 692 CSRMatrix\n",
            "(0,272) 0.0001\n",
            "(0,300) 0.0001\n",
            "(0,350) -0.0002\n",
            "(0,351) -0.0001\n",
            "(0,378) -0.0003\n",
            "(0,379) -0.0002\n",
            "(0,405) -0.0002\n",
            "(0,406) -0.0004\n",
            "(0,407) -0.0002\n",
            "(0,433) -0.0003\n",
            "(0,434) -0.0005\n",
            "(0,435) -0.0001\n",
            "(0,456) 0.0\n",
            "(0,461) -0.0002\n",
            "(0,462) -0.0004\n",
            "(0,483) 0.0001\n",
            "..\n",
            "..\n",
            "Multinomial intercepts: [0.2750587585718093,-0.2750587585718093]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "# Extract the summary from the returned LogisticRegressionModel instance trained\n",
        "# in the earlier example\n",
        "trainingSummary = lrModel.summary\n"
      ],
      "metadata": {
        "id": "7XH5q7q5JCjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Obtain the objective per iteration\n",
        "objectiveHistory = trainingSummary.objectiveHistory\n",
        "print(\"objectiveHistory:\")\n",
        "for objective in objectiveHistory:\n",
        "    print(objective)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pq1M7hHPJFiV",
        "outputId": "10971831-60ce-4dcf-9d06-bddd1703291d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objectiveHistory:\n",
            "0.6833149135741672\n",
            "0.6661906127558117\n",
            "0.6207433672479603\n",
            "0.6131541253123871\n",
            "0.6059149689952394\n",
            "0.5923656241678249\n",
            "0.589823308283802\n",
            "0.5868012627420285\n",
            "0.5844432058719141\n",
            "0.5830790068041746\n",
            "0.5807015754032353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.\n",
        "trainingSummary.roc.show()\n",
        "print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfmYrI4hJH0c",
        "outputId": "7b944884-d13c-4a1b-8923-08da3c3b7df6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/context.py:127: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------+\n",
            "|FPR|                 TPR|\n",
            "+---+--------------------+\n",
            "|0.0|                 0.0|\n",
            "|0.0|0.017543859649122806|\n",
            "|0.0| 0.03508771929824561|\n",
            "|0.0| 0.05263157894736842|\n",
            "|0.0| 0.07017543859649122|\n",
            "|0.0| 0.08771929824561403|\n",
            "|0.0| 0.10526315789473684|\n",
            "|0.0| 0.12280701754385964|\n",
            "|0.0| 0.14035087719298245|\n",
            "|0.0| 0.15789473684210525|\n",
            "|0.0| 0.17543859649122806|\n",
            "|0.0| 0.19298245614035087|\n",
            "|0.0| 0.21052631578947367|\n",
            "|0.0| 0.22807017543859648|\n",
            "|0.0| 0.24561403508771928|\n",
            "|0.0|  0.2631578947368421|\n",
            "|0.0|  0.2807017543859649|\n",
            "|0.0|  0.2982456140350877|\n",
            "|0.0|  0.3157894736842105|\n",
            "|0.0|  0.3333333333333333|\n",
            "+---+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "areaUnderROC: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model threshold to maximize F-Measure\n",
        "fMeasure = trainingSummary.fMeasureByThreshold\n",
        "maxFMeasure = fMeasure.groupBy().max('F-Measure').select('max(F-Measure)').head()\n",
        "bestThreshold = fMeasure.where(fMeasure['F-Measure'] == maxFMeasure['max(F-Measure)']) \\\n",
        "    .select('threshold').head()['threshold']\n",
        "lr.setThreshold(bestThreshold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTHpHQbbJKfU",
        "outputId": "6e13270e-be68-45a2-a7e7-12463b6216e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/context.py:127: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression_e6af9d25e5ee"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multinomial Logistics Regression"
      ],
      "metadata": {
        "id": "4RZi7HIbJVS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "# Load training data\n",
        "df = spark.read.format(\"libsvm\").load(\"/content/drive/MyDrive/0.MKCE/20.ML with Spark/sample_multiclass_classification_data.txt\")\n",
        "############################################\n",
        "# Load training data\n",
        "#training = spark \\\n",
        "#    .read \\\n",
        "#    .format(\"libsvm\") \\\n",
        "#    .load(\"data/mllib/sample_multiclass_classification_data.txt\")\n",
        "#################################"
      ],
      "metadata": {
        "id": "-YGbEd1YJSoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n"
      ],
      "metadata": {
        "id": "OQtLbKLPJYPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Fit the model\n",
        "lrModel = lr.fit(df)\n"
      ],
      "metadata": {
        "id": "acrC5i4kJcch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Print the coefficients and intercept for multinomial logistic regression\n",
        "print(\"Coefficients: \\n\" + str(lrModel.coefficientMatrix))\n",
        "print(\"Intercept: \" + str(lrModel.interceptVector))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbZKGJaPJfGb",
        "outputId": "452acbad-8d93-4527-edcf-4166a2989146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: \n",
            "3 X 4 CSRMatrix\n",
            "(0,3) 0.305\n",
            "(1,2) -0.7666\n",
            "(1,3) -0.3854\n",
            "Intercept: [0.05192580020728831,-0.12619173083598803,0.07426593062869971]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "trainingSummary = lrModel.summary\n"
      ],
      "metadata": {
        "id": "dleAs7z7JiIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Obtain the objective per iteration\n",
        "objectiveHistory = trainingSummary.objectiveHistory\n",
        "print(\"objectiveHistory:\")\n",
        "for objective in objectiveHistory:\n",
        "    print(objective)\n"
      ],
      "metadata": {
        "id": "OkXJEZeUJliA",
        "outputId": "10a1730e-bc4d-4d79-b41f-64102d91f882",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "objectiveHistory:\n",
            "1.098612288668108\n",
            "1.0767872580801818\n",
            "1.0324898663050683\n",
            "1.0276148685544233\n",
            "1.0292979666409194\n",
            "1.0238563624020458\n",
            "1.0236260835897755\n",
            "1.0235478802964153\n",
            "1.0231925082158748\n",
            "1.0231565244620064\n",
            "1.0229939986213705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4GiDA7llJnrq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}